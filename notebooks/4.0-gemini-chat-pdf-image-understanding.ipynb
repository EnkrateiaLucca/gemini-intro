{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini App Chatting with PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"var: \")\n",
    "\n",
    "_set_env(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-01 12:23:59--  https://arxiv.org/pdf/2308.03688\n",
      "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.3.42, 151.101.67.42, ...\n",
      "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23176585 (22M) [application/pdf]\n",
      "Saving to: ‘2308.03688’\n",
      "\n",
      "2308.03688          100%[===================>]  22.10M   105MB/s    in 0.2s    \n",
      "\n",
      "2025-05-01 12:23:59 (105 MB/s) - ‘2308.03688’ saved [23176585/23176585]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!wget https://arxiv.org/pdf/2308.03688 && mv 2308.03688 ./paper.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is a technical report introducing AgentBench, a new benchmark for evaluating the performance of large language models (LLMs) as agents in interactive environments. The report details the design of AgentBench, which includes eight distinct environments spanning code, game, and web domains, and presents a thorough evaluation of 27 LLMs, both API-based commercial models and open-source models. The results indicate a significant performance gap between commercial and open-source LLMs and identify common failure reasons, such as poor long-term reasoning and instruction following. The report also discusses potential improvements through code training and higher-quality alignment data and introduces an integrated evaluation toolkit for facilitating future research.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import httpx\n",
    "import os\n",
    "\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=gemini_api_key)\n",
    "\n",
    "doc_url = \"https://arxiv.org/pdf/2308.03688\"\n",
    "\n",
    "# Retrieve and encode the PDF byte\n",
    "doc_data = httpx.get(doc_url).content\n",
    "\n",
    "prompt = \"Summarize this document\"\n",
    "response = client.models.generate_content(\n",
    "  model=\"gemini-2.0-flash\",\n",
    "  contents=[\n",
    "      types.Part.from_bytes(\n",
    "        data=doc_data,\n",
    "        mime_type='application/pdf',\n",
    "      ),\n",
    "      prompt])\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
